{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"7eQVAttPTYfE"},"outputs":[],"source":["#@title Run The Training Model\n","!pip3 install faiss-cpu==1.7.2\n","!pip3 install fairseq gradio==3.14.0\n","!pip3 install ffmpeg\n","!pip3 install ffmpeg-python\n","!pip3 install praat-parselmouth\n","!pip3 install pyworld numpy==1.23.5\n","!pip3 install numba==0.56.4\n","!pip3 install librosa==0.9.2\n","from google.colab import drive\n","drive.mount('/content/drive')\n","!cp -r /content/drive/MyDrive/Project/Deepfake/Code/DeepFakeV2 /content/\n","!cp /content/drive/MyDrive/Project/Deepfake/Models/RVC-V2/weights/*.pth  /content/DeepFakeV2/assets/weights\n","!cp -r /content/drive/MyDrive/Project/Deepfake/Models/RVC-V2/modiji /content/drive/MyDrive/Project/Deepfake/Code/DeepFakeV2/logs\n","!pip install python-dotenv\n","!pip  install -r /content/DeepFakeV2/requirements.txt\n","%cd /content/DeepFakeV2"]},{"cell_type":"code","source":["!cp -r /content/drive/MyDrive/RVC/jayeshsir /content/DeepFakeV2/logs\n","!cp /content/drive/MyDrive/RVC/weights/jayeshsir.pth /content/DeepFakeV2/assets/weights"],"metadata":{"id":"eNU6IkLaazl5"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["e5e7bc2953714a32b80343b172dd8dce","cebebf6f9bdc4df7bba4e120627d3651","763af665666142a7bd076dc38526f284"]},"executionInfo":{"elapsed":81324,"status":"ok","timestamp":1696917762020,"user":{"displayName":"Om patil","userId":"12194563682376089996"},"user_tz":-330},"id":"w4wXvoez9Rce","outputId":"34809c82-17e0-412f-e036-870af5e9dc12"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Button(button_style='success', description='✔ Success', style=ButtonStyle())"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5e7bc2953714a32b80343b172dd8dce"}},"metadata":{}}],"source":["#@title 1.Preprocess Data\n","import os\n","from IPython.display import clear_output\n","from ipywidgets import Button\n","%cd /content/DeepFakeV2/\n","model_name = 'modiji' #@param {type:\"string\"}\n","#@markdown <small> Enter the path to your dataset, or if you want just upload the audios using the File Manager into the 'dataset' folder.\n","dataset_folder = '/content/drive/MyDrive/Project/Deepfake/Datasets/RVC' #@param {type:\"string\"}\n","while len(os.listdir(dataset_folder)) < 1:\n","    input(\"Your dataset folder is empty.\")\n","!mkdir -p ./logs/{model_name}\n","with open(f'./logs/{model_name}/preprocess.log','w') as f:\n","    print(\"Starting...\")\n","!python infer/modules/train/preprocess.py {dataset_folder} 40000 2 ./logs/{model_name} False 3.0 > /dev/null 2>&1\n","with open(f'./logs/{model_name}/preprocess.log','r') as f:\n","    if 'end preprocess' in f.read():\n","        clear_output()\n","        display(Button(description=\"\\u2714 Success\", button_style=\"success\"))\n","    else:\n","        print(\"Error preprocessing data... Make sure your dataset folder is correct.\")\n","f0method = \"harvest\" # @param [\"pm\", \"harvest\", \"rmvpe\", \"rmvpe_gpu\"]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["c9d6f8dd7cce48209743dc3fed58841d","8f94ed760ccf496ca19e9b6b486e344e","24a4778ac682471fb579a08c9e5a315d"]},"executionInfo":{"elapsed":1317387,"status":"ok","timestamp":1696919079294,"user":{"displayName":"Om patil","userId":"12194563682376089996"},"user_tz":-330},"id":"fMf6iAqHk68w","outputId":"3cb872df-c381-4134-a907-a26962c3314d"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Button(button_style='success', description='✔ Success', style=ButtonStyle())"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9d6f8dd7cce48209743dc3fed58841d"}},"metadata":{}}],"source":["#@title 2. Feature Index\n","%cd /content/DeepFakeV2/\n","with open(f'./logs/{model_name}/extract_f0_feature.log','w') as f:\n","    print(\"Starting...\")\n","if f0method != \"rmvpe_gpu\":\n","    !python infer/modules/train/extract/extract_f0_print.py ./logs/{model_name} 2 {f0method}\n","else:\n","    !python infer/modules/train/extract/extract_f0_rmvpe.py 1 0 0 ./logs/{model_name} True\n","!python infer/modules/train/extract_feature_print.py cuda:0 1 0 0 ./logs/{model_name} v2\n","with open(f'./logs/{model_name}/extract_f0_feature.log','r') as f:\n","    if 'all-feature-done' in f.read():\n","        clear_output()\n","        display(Button(description=\"\\u2714 Success\", button_style=\"success\"))\n","    else:\n","        print(\"Error preprocessing data... Make sure your data was preprocessed.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["158dd4d2e2ff4c98a4625270131ce30b","265a49af88944537a42c5801b14f312b","6f010d1d40014045bfaff7c3ec3cede6"]},"id":"3KyMRbK49g__","outputId":"08c5909e-efe0-489f-d715-f3336f76eb0a","executionInfo":{"status":"ok","timestamp":1696919235600,"user_tz":-330,"elapsed":156347,"user":{"displayName":"Om patil","userId":"12194563682376089996"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["Button(button_style='success', description='✔ Success', style=ButtonStyle())"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"158dd4d2e2ff4c98a4625270131ce30b"}},"metadata":{}}],"source":["#@title 3.Train Index\n","import numpy as np\n","import faiss\n","%cd /content/DeepFakeV2\n","def train_index(exp_dir1, version19):\n","    exp_dir = \"logs/%s\" % (exp_dir1)\n","    os.makedirs(exp_dir, exist_ok=True)\n","    feature_dir = (\n","        \"%s/3_feature256\" % (exp_dir)\n","        if version19 == \"v1\"\n","        else \"%s/3_feature768\" % (exp_dir)\n","    )\n","    if not os.path.exists(feature_dir):\n","        return \"请先进行特征提取!\"\n","    listdir_res = list(os.listdir(feature_dir))\n","    if len(listdir_res) == 0:\n","        return \"请先进行特征提取！\"\n","    infos = []\n","    npys = []\n","    for name in sorted(listdir_res):\n","        phone = np.load(\"%s/%s\" % (feature_dir, name))\n","        npys.append(phone)\n","    big_npy = np.concatenate(npys, 0)\n","    big_npy_idx = np.arange(big_npy.shape[0])\n","    np.random.shuffle(big_npy_idx)\n","    big_npy = big_npy[big_npy_idx]\n","    if big_npy.shape[0] > 2e5:\n","        infos.append(\"Trying doing kmeans %s shape to 10k centers.\" % big_npy.shape[0])\n","        yield \"\\n\".join(infos)\n","        try:\n","            big_npy = (\n","                MiniBatchKMeans(\n","                    n_clusters=10000,\n","                    verbose=True,\n","                    batch_size=256 * config.n_cpu,\n","                    compute_labels=False,\n","                    init=\"random\",\n","                )\n","                .fit(big_npy)\n","                .cluster_centers_\n","            )\n","        except:\n","            info = traceback.format_exc()\n","            logger.info(info)\n","            infos.append(info)\n","            yield \"\\n\".join(infos)\n","\n","    np.save(\"%s/total_fea.npy\" % exp_dir, big_npy)\n","    n_ivf = min(int(16 * np.sqrt(big_npy.shape[0])), big_npy.shape[0] // 39)\n","    infos.append(\"%s,%s\" % (big_npy.shape, n_ivf))\n","    yield \"\\n\".join(infos)\n","    index = faiss.index_factory(256 if version19 == \"v1\" else 768, \"IVF%s,Flat\" % n_ivf)\n","    infos.append(\"training\")\n","    yield \"\\n\".join(infos)\n","    index_ivf = faiss.extract_index_ivf(index)  #\n","    index_ivf.nprobe = 1\n","    index.train(big_npy)\n","    faiss.write_index(\n","        index,\n","        \"%s/trained_IVF%s_Flat_nprobe_%s_%s_%s.index\"\n","        % (exp_dir, n_ivf, index_ivf.nprobe, exp_dir1, version19),\n","    )\n","\n","    infos.append(\"adding\")\n","    yield \"\\n\".join(infos)\n","    batch_size_add = 8192\n","    for i in range(0, big_npy.shape[0], batch_size_add):\n","        index.add(big_npy[i : i + batch_size_add])\n","    faiss.write_index(\n","        index,\n","        \"%s/added_IVF%s_Flat_nprobe_%s_%s_%s.index\"\n","        % (exp_dir, n_ivf, index_ivf.nprobe, exp_dir1, version19),\n","    )\n","    infos.append(\n","        \"成功构建索引，added_IVF%s_Flat_nprobe_%s_%s_%s.index\"\n","        % (n_ivf, index_ivf.nprobe, exp_dir1, version19)\n","    )\n","\n","training_log = train_index(model_name, 'v2')\n","\n","for line in training_log:\n","    print(line)\n","    if 'adding' in line:\n","        clear_output()\n","        display(Button(description=\"\\u2714 Success\", button_style=\"success\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"FFfC9x239kC1"},"outputs":[],"source":["#@title 4.Train Model\n","%cd /content/DeepFakeV2\n","from random import shuffle\n","import json\n","import os\n","import pathlib\n","from subprocess import Popen, PIPE, STDOUT\n","now_dir=os.getcwd()\n","#@markdown <small> Enter the name of your model again. It must be the same you chose before.\n","model_name = 'modiji'#@param {type:\"string\"}\n","#@markdown <small> Choose how often to save the model and how much training you want it to have.\n","save_frequency = 30 # @param {type:\"slider\", min:5, max:50, step:5}\n","epochs = 210 # @param {type:\"slider\", min:10, max:1000, step:10}\n","#@markdown <small> ONLY cache datasets under 10 minutes long. Otherwise leave this unchecked.\n","cache = False #@param {type:\"boolean\"}\n","# Remove the logging setup\n","\n","def click_train(\n","    exp_dir1,\n","    sr2,\n","    if_f0_3,\n","    spk_id5,\n","    save_epoch10,\n","    total_epoch11,\n","    batch_size12,\n","    if_save_latest13,\n","    pretrained_G14,\n","    pretrained_D15,\n","    gpus16,\n","    if_cache_gpu17,\n","    if_save_every_weights18,\n","    version19,\n","):\n","    # 生成filelist\n","    exp_dir = \"%s/logs/%s\" % (now_dir, exp_dir1)\n","    os.makedirs(exp_dir, exist_ok=True)\n","    gt_wavs_dir = \"%s/0_gt_wavs\" % (exp_dir)\n","    feature_dir = (\n","        \"%s/3_feature256\" % (exp_dir)\n","        if version19 == \"v1\"\n","        else \"%s/3_feature768\" % (exp_dir)\n","    )\n","    if if_f0_3:\n","        f0_dir = \"%s/2a_f0\" % (exp_dir)\n","        f0nsf_dir = \"%s/2b-f0nsf\" % (exp_dir)\n","        names = (\n","            set([name.split(\".\")[0] for name in os.listdir(gt_wavs_dir)])\n","            & set([name.split(\".\")[0] for name in os.listdir(feature_dir)])\n","            & set([name.split(\".\")[0] for name in os.listdir(f0_dir)])\n","            & set([name.split(\".\")[0] for name in os.listdir(f0nsf_dir)])\n","        )\n","    else:\n","        names = set([name.split(\".\")[0] for name in os.listdir(gt_wavs_dir)]) & set(\n","            [name.split(\".\")[0] for name in os.listdir(feature_dir)]\n","        )\n","    opt = []\n","    for name in names:\n","        if if_f0_3:\n","            opt.append(\n","                \"%s/%s.wav|%s/%s.npy|%s/%s.wav.npy|%s/%s.wav.npy|%s\"\n","                % (\n","                    gt_wavs_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n","                    name,\n","                    feature_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n","                    name,\n","                    f0_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n","                    name,\n","                    f0nsf_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n","                    name,\n","                    spk_id5,\n","                )\n","            )\n","        else:\n","            opt.append(\n","                \"%s/%s.wav|%s/%s.npy|%s\"\n","                % (\n","                    gt_wavs_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n","                    name,\n","                    feature_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n","                    name,\n","                    spk_id5,\n","                )\n","            )\n","    fea_dim = 256 if version19 == \"v1\" else 768\n","    if if_f0_3:\n","        for _ in range(2):\n","            opt.append(\n","                \"%s/logs/mute/0_gt_wavs/mute%s.wav|%s/logs/mute/3_feature%s/mute.npy|%s/logs/mute/2a_f0/mute.wav.npy|%s/logs/mute/2b-f0nsf/mute.wav.npy|%s\"\n","                % (now_dir, sr2, now_dir, fea_dim, now_dir, now_dir, spk_id5)\n","            )\n","    else:\n","        for _ in range(2):\n","            opt.append(\n","                \"%s/logs/mute/0_gt_wavs/mute%s.wav|%s/logs/mute/3_feature%s/mute.npy|%s\"\n","                % (now_dir, sr2, now_dir, fea_dim, spk_id5)\n","            )\n","    shuffle(opt)\n","    with open(\"%s/filelist.txt\" % exp_dir, \"w\") as f:\n","        f.write(\"\\n\".join(opt))\n","\n","    # Replace logger.debug, logger.info with print statements\n","    print(\"Write filelist done\")\n","    print(\"Use gpus:\", str(gpus16))\n","    if pretrained_G14 == \"\":\n","        print(\"No pretrained Generator\")\n","    if pretrained_D15 == \"\":\n","        print(\"No pretrained Discriminator\")\n","    if version19 == \"v1\" or sr2 == \"40k\":\n","        config_path = \"configs/v1/%s.json\" % sr2\n","    else:\n","        config_path = \"configs/v2/%s.json\" % sr2\n","    config_save_path = os.path.join(exp_dir, \"config.json\")\n","    if not pathlib.Path(config_save_path).exists():\n","        with open(config_save_path, \"w\", encoding=\"utf-8\") as f:\n","            with open(config_path, \"r\") as config_file:\n","                config_data = json.load(config_file)\n","                json.dump(\n","                    config_data,\n","                    f,\n","                    ensure_ascii=False,\n","                    indent=4,\n","                    sort_keys=True,\n","                )\n","            f.write(\"\\n\")\n","\n","    cmd = (\n","        'python infer/modules/train/train.py -e \"%s\" -sr %s -f0 %s -bs %s -g %s -te %s -se %s %s %s -l %s -c %s -sw %s -v %s'\n","        % (\n","            exp_dir1,\n","            sr2,\n","            1 if if_f0_3 else 0,\n","            batch_size12,\n","            gpus16,\n","            total_epoch11,\n","            save_epoch10,\n","            \"-pg %s\" % pretrained_G14 if pretrained_G14 != \"\" else \"\",\n","            \"-pd %s\" % pretrained_D15 if pretrained_D15 != \"\" else \"\",\n","            1 if if_save_latest13 == True else 0,\n","            1 if if_cache_gpu17 == True else 0,\n","            1 if if_save_every_weights18 == True else 0,\n","            version19,\n","        )\n","    )\n","    # Use PIPE to capture the output and error streams\n","    p = Popen(cmd, shell=True, cwd=now_dir, stdout=PIPE, stderr=STDOUT, bufsize=1, universal_newlines=True)\n","\n","    # Print the command's output as it runs\n","    for line in p.stdout:\n","        print(line.strip())\n","\n","    # Wait for the process to finish\n","    p.wait()\n","    return \"训练结束, 您可查看控制台训练日志或实验文件夹下的train.log\"\n","%load_ext tensorboard\n","%tensorboard --logdir ./logs\n","training_log = click_train(\n","    model_name,\n","    '40k',\n","    True,\n","    0,\n","    save_frequency,\n","    epochs,\n","    7,\n","    True,\n","    'assets/pretrained_v2/f0G40k.pth',\n","    'assets/pretrained_v2/f0D40k.pth',\n","    0,\n","    cache,\n","    True,\n","    'v2',\n",")\n","print(training_log)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4CD1PeJL2EiB"},"outputs":[],"source":["!cp /content/DeepFakeV2/assets/weights/*.pth /content/drive/MyDrive/Project/Deepfake/Models/RVC-V2/weights/\n","!cp  /content/DeepFakeV2/logs/modiji/D_2333333.pth /content/drive/MyDrive/Project/Deepfake/Models/RVC-V2/modiji/\n","!cp /content/DeepFakeV2/logs/modiji/G_2333333.pth /content/drive/MyDrive/Project/Deepfake/Models/RVC-V2/modiji/\n","!cp /content/DeepFakeV2/logs/modiji/added_IVF3534_Flat_nprobe_1_modiji_v2.index /content/drive/MyDrive/Project/Deepfake/Models/RVC-V2/modiji/\n","!cp /content/DeepFakeV2/logs/modiji/trained_IVF3534_Flat_nprobe_1_modiji_v2.index /content/drive/MyDrive/Project/Deepfake/Models/RVC-V2/modiji/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QseXGNw-ZV4M"},"outputs":[],"source":["!python3 infer-web.py --colab --pycmd python3"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"e5e7bc2953714a32b80343b172dd8dce":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"success","description":"✔ Success","disabled":false,"icon":"","layout":"IPY_MODEL_cebebf6f9bdc4df7bba4e120627d3651","style":"IPY_MODEL_763af665666142a7bd076dc38526f284","tooltip":""}},"cebebf6f9bdc4df7bba4e120627d3651":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"763af665666142a7bd076dc38526f284":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"c9d6f8dd7cce48209743dc3fed58841d":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"success","description":"✔ Success","disabled":false,"icon":"","layout":"IPY_MODEL_8f94ed760ccf496ca19e9b6b486e344e","style":"IPY_MODEL_24a4778ac682471fb579a08c9e5a315d","tooltip":""}},"8f94ed760ccf496ca19e9b6b486e344e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"24a4778ac682471fb579a08c9e5a315d":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"158dd4d2e2ff4c98a4625270131ce30b":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"success","description":"✔ Success","disabled":false,"icon":"","layout":"IPY_MODEL_265a49af88944537a42c5801b14f312b","style":"IPY_MODEL_6f010d1d40014045bfaff7c3ec3cede6","tooltip":""}},"265a49af88944537a42c5801b14f312b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f010d1d40014045bfaff7c3ec3cede6":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}}}}},"nbformat":4,"nbformat_minor":0}